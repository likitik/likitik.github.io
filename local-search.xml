<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>GOODS谷歌数据湖管理系统</title>
    <link href="/2020/07/17/GOODS%E8%B0%B7%E6%AD%8C%E6%95%B0%E6%8D%AE%E6%B9%96%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/"/>
    <url>/2020/07/17/GOODS%E8%B0%B7%E6%AD%8C%E6%95%B0%E6%8D%AE%E6%B9%96%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="Managing-Google’s-data-lake-an-overview-of-the-GOODS-system"><a href="#Managing-Google’s-data-lake-an-overview-of-the-GOODS-system" class="headerlink" title="Managing Google’s data lake: an overview of the GOODS system"></a>Managing Google’s data lake: an overview of the GOODS system</h1><blockquote><p>会议：Bulletin of the IEEE Computer Society Technical Committee on Data Engineering</p><p>year：2016</p></blockquote><p>In many cases, engineers and data scientists do not use centralized data-management systems and end up creating what became known as a data lake—a collection of datasets that often are not well organized or not organized at all and where one needs to “ﬁsh” for useful datasets. </p><p><strong>数据湖</strong>：半结构化或非结构化的数据集合，是一种把各类异构数据进行集中存储的架构</p><ul><li>由于企业内部数据的爆发增长，而关于数据的目的，价值，来源的各种信息不全，导致数据被孤立在数据来源的团队中，从而造成机会和生产力的重大损失。</li></ul><h2 id="GOODS-system：Google-Dataset-Search"><a href="#GOODS-system：Google-Dataset-Search" class="headerlink" title="GOODS system：Google Dataset Search"></a>GOODS system：Google Dataset Search</h2><ul><li><p>组织，管理数据湖中数据集的系统</p></li><li><p>GOODS operates in a <strong>post-hoc</strong> manner：先有数据集后有元数据，即入湖之后再收集和聚合数据集的元数据。</p></li><li><p>It infers metadata and relationships among datasets by processing additional sources such as logs and information about dataset owners and their projects, by analyzing content of the datasets, and by collecting input from the G OODS users.</p></li><li><p>如何推断出数据集的元数据信息？</p><ul><li>通过分析数据集内容</li><li>通过处理额外的信息，如日志，用户信息，项目信息</li><li>通过用户输入的信息</li></ul><img src="https://cdn.jsdelivr.net/gh/likitik/helloworld@master/img/image-20200716095229246.png" srcset="/img/loading.gif" alt="image-20200716095229246" style="zoom:67%;" /></li><li><p>GOODS不断爬取不同的存储系统和生产基础设施(例如，运行管道中的日志)，以发现存在哪些数据集，并收集关于每个数据集的元数据(例如，所有者、访问时间、内容特性、访问连接)。</p></li><li><p>GOODS在一个中央目录中聚合这些元数据，并关联特定数据集的元数据与其他数据集信息。然后，GOODS使用这个目录为谷歌工程师提供数据集管理服务。（<strong>数据价值</strong>）</p><ul><li>覆盖所有数据集的搜索引擎，具有缩小搜索结果的功能，帮助工程师和分析师找到最相关的数据集。</li><li>数据集配置文件页面，显示GOODS记录的关于特定数据集的元数据，从而帮助用户理解数据集本身和与其他数据集的关系。配置文件页面与其他工具集成，提供对数据集的进一步处理能力，帮助用户对数据进行操作。</li><li>一个监视服务，允许团队监视他们拥有的数据集的特性，例如大小、内容中值的分布和可用性。用户可以配置此监视服务，以便在功能意外更改时发出警报。</li><li>一个注释服务，允许用户扩展数据集的元数据与在某些领域特定的注释，可以出现在配置文件页面。例如，数据集所有者可以为数据集的内容提供文本描述，或者附加一个可视化工具。</li></ul></li></ul><h3 id="元数据发现能力"><a href="#元数据发现能力" class="headerlink" title="元数据发现能力"></a>元数据发现能力</h3><p>数据湖管理系统的主要目标是为其中的数据集收集元数据。我们可以独立地查看每个数据集的元数据。</p><h4 id="场景价值"><a href="#场景价值" class="headerlink" title="场景价值"></a>场景价值</h4><ul><li><p>规范审核：schema审核团队用来审核其他团队的数据集模式，从而确保其数据集符合使用规范</p></li><li><p>数据血缘：元数据发现产生的元数据信息包含数据源链接，<em>即数据集X是由生产作业Y产生的</em>，从而形成完整的数据链接的传递闭包，形成数据集谱系依赖关系，对于团队A，希望使用数据集B，但是发现数据集B被过度修饰过了，那么通过谱系可以容易的找到数据集B的上游数据集C，从而完成自己的任务。</p></li><li><p>可视化：通过注释服务把可视化附加到用于ML pipelines的训练数据集上，从而帮助用户理解特征的分布。</p></li></ul><h3 id="构建企业数据湖的挑战"><a href="#构建企业数据湖的挑战" class="headerlink" title="构建企业数据湖的挑战"></a>构建企业数据湖的挑战</h3><h4 id="如何收集，识别，推断，关联元数据"><a href="#如何收集，识别，推断，关联元数据" class="headerlink" title="如何收集，识别，推断，关联元数据"></a>如何收集，识别，推断，关联元数据</h4><p>两个例子：</p><ul><li>查找项目X拥有的所有数据集。如果计划删除X项目拥有的数据集，需要通知哪些团队。这个查询需要了解不同团队的组成、数据集所有权和起源关系。</li><li>查找特定版本的代码中方法X的生产作业所编写的所有数据集。这可以帮助识别可能受到错误代码影响的数据集。</li></ul><p>问题：</p><ul><li>不能通过穷举扫描大规模数据集，不可能逐个比较</li><li>使用生产数据集的作业日志来识别血缘，但不同团队，不同作业的日志格式是不同的</li></ul><h4 id="元数据提取需要可伸缩"><a href="#元数据提取需要可伸缩" class="headerlink" title="元数据提取需要可伸缩"></a>元数据提取需要可伸缩</h4><p>问题：</p><ul><li>数据规模超大</li><li>数据集每天都有大规模的新增和删除</li><li>有很大一部分短暂存在的数据集</li><li>提取单个数据集的元数据成本很高，需要读取文件存储系统中的文件内容</li></ul><p>解决：</p><ul><li>数据集优先级排序</li></ul><h4 id="Post-hoc-Management-of-Metadata"><a href="#Post-hoc-Management-of-Metadata" class="headerlink" title="Post-hoc Management of Metadata"></a>Post-hoc Management of Metadata</h4><p>​    传统的企业数据管理系统需要规定设计特定的API来访问数据集，可以提供非常精确的元数据管理，但是需要进入系统前组织好元数据。而数据湖希望不影响团队实践的前提下组织并产生价值。</p><p>问题：</p><ul><li><p>面对不同存储格式，有对应的解析工具，可能产生多种候选的模式</p></li><li><p>跨各种异构的数据源，统一视图</p></li></ul><h3 id="数据湖关系图"><a href="#数据湖关系图" class="headerlink" title="数据湖关系图"></a>数据湖关系图</h3><p>建立数据集与数据集之间，数据集与其他实体（如生产作业，项目，用户，代码等等）之间的关系图谱</p><ul><li>数据集包含关系，例如bigtable的列族是一级条目，而bigtable本身也是一级条目。</li><li>数据集的产生，使用，依赖等<ul><li>如日志数据，可能访问事件巨大，需要抽样，并在几个跳内物化上下游关系。</li></ul></li><li>按时间等维度划分数据集，按照不同维度组合层次关系，每个节点对应不同粒度查看数据集。<strong><em>分区表</em></strong></li><li>内容相似性，包括数据集整体级别和单个列级别。考虑数据集规模，依靠近似技术来确定哪些数据集是彼此的副本，哪些数据集具有不同的内容。通过单字段校验和+LSH（locality-sensitive hash）相似度来生成数据集指纹，从而进行数据集整体和列级别比较。<ul><li>LSH算法</li></ul></li></ul><h3 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h3><h4 id="利用关系图"><a href="#利用关系图" class="headerlink" title="利用关系图"></a>利用关系图</h4><p>以牺牲精度为代价，避免识别每个成员，节省元数据提取，提高性能。</p><ul><li>相同集群，少数数据集的元数据可以代表整体，并传播到相似集群</li><li>相同作业产生的不同版本数据集，通常是相同schema，不需要识别每个版本</li><li>用户已经提供的数据集描述，可以覆盖应用到整个数据集的元数据</li><li>元数据提取过于昂贵时，可以通过关联数据集传播的方式传播元数据</li></ul><p>可以支持各种链接</p><ul><li><p>从源代码的schema定义处跳转到使用该模式的所有数据集目录</p></li><li><p>团队新成员找到该团队产生的所有数据集列表目录</p></li><li><p>数据集配置页面跳转到拥有者所有数据集列表目录</p><p>。。。</p></li></ul><h4 id="模块设计"><a href="#模块设计" class="headerlink" title="模块设计"></a>模块设计</h4><ul><li>GOODS后端使用大量不同的批处理作业从各种系统收集信息，并将新信息添加和更新到GOODS目录中。</li><li>首先，各模块优先级问题<ul><li>识别数据集存在，所属等基本信息，对于确保系统状态最新和数据集访问控制变化至关重要。</li><li>schema analyzer识别模式的模块时间敏感性不高，可以利用空闲时间。</li></ul></li><li>第二，各模块依赖关系问题<ul><li>将依赖模块尽可能分到同组中，可以减少从后端持久存储读取的总字节数。</li></ul></li><li>第三，对故障模块的隔离<ul><li>检查数据集内容的模块会使用不同的schemaReader库，可能造成崩溃和循环，所以应该在单独的进程沙箱化的处理这些危险作业，并使用监视线程将长暂停转换为崩溃。</li></ul></li><li>最后，不同模块计算复杂度不同，资源占用情况也不同。<ul><li>避免重新运行计算昂贵的模块。</li></ul></li></ul><h4 id="搜索排名"><a href="#搜索排名" class="headerlink" title="搜索排名"></a>搜索排名</h4><p>对于数据集搜索系统，如何对结果排序？</p><p>用户搜索目的应该影响搜索排名结果，即数据湖管理系统应支持多种排序方法，并允许用户在搜索时选择使用哪种！</p><h3 id="未来的发展方向"><a href="#未来的发展方向" class="headerlink" title="未来的发展方向"></a>未来的发展方向</h3><ul><li>数据集社区文化，允许用户共享和交换数据集的信息，并在目录中增加领域特定知识的元数据。目标是共同管理数据湖。可以添加更多类似于社区的功能，包括对数据集的评论、问答功能等等。其目标是培养联合数据管理的文化，以及向数据湖中添加新数据集的最佳实践。</li><li>支持比较数据湖快照，从而发现趋势。</li><li>通过连续查询监控数据湖内容</li><li>丰富的数据分析对数据湖是有价值的</li><li>因为需要通过post-hoc的方式分析数据集，所以会有时延，而对于希望实时的用户，提供一种混合方法，即为这些团队提供注册数据集和向数据目录中贡献元数据的api。</li><li>数据湖的元数据信息不仅要帮助用户理解数据集，也要让用户发现数据集的价值，可以做什么，可以如何在其他工具中使用数据湖。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>数据湖</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何防止数据湖变成数据沼泽</title>
    <link href="/2020/07/13/%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2%E6%95%B0%E6%8D%AE%E6%B9%96%E5%8F%98%E6%88%90%E6%95%B0%E6%8D%AE%E6%B2%BC%E6%B3%BD/"/>
    <url>/2020/07/13/%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2%E6%95%B0%E6%8D%AE%E6%B9%96%E5%8F%98%E6%88%90%E6%95%B0%E6%8D%AE%E6%B2%BC%E6%B3%BD/</url>
    
    <content type="html"><![CDATA[<blockquote><p>数据湖可以存储所有结构化与非结构化数据，但是庞大的存储库会瘫痪，如何防止数据湖变成数据沼泽。</p></blockquote><h3 id="数据沼泽"><a href="#数据沼泽" class="headerlink" title="数据沼泽"></a>数据沼泽</h3><p>​        企业希望建立一个数据湖，能够将所有数据以原生格式存储，从而打破数据孤岛，成为一个单一的数据存储库，使从业务分析到数据挖掘的所有事都可以在数据湖中解决。</p><p>​        但是很多数据湖最后都恶化为了终端用户完全无法访问的海量数据仓库-数据沼泽。一些公司成功的围绕数据湖建立了业务，而另一些却只是收集数据，没有明确的方法从中获得价值。变成了收集垃圾，最终被遗弃。</p><h3 id="三条原则"><a href="#三条原则" class="headerlink" title="三条原则"></a>三条原则</h3><h4 id="至少一开始只收集更少的数据"><a href="#至少一开始只收集更少的数据" class="headerlink" title="至少一开始只收集更少的数据"></a>至少一开始只收集更少的数据</h4><p>​        由于hadoop中存储数据十分廉价，甚至被认为是免费的，收集数据的成本低并不意味这使用数据的成本也低，对于一个数据集要有一个具体的计划挖掘它，而不是随时随地的收集信息。</p><h4 id="采用机器学习策略"><a href="#采用机器学习策略" class="headerlink" title="采用机器学习策略"></a>采用机器学习策略</h4><p>​        需要一个自动化的系统来清理数据集</p><h4 id="明确要解决的业务问题"><a href="#明确要解决的业务问题" class="headerlink" title="明确要解决的业务问题"></a>明确要解决的业务问题</h4><p>​        要有要解决的业务问题，有了目标从而相对容易的所锁定要收集的数据以及从数据中收集洞察的最佳机器学习技术。</p><h3 id="个人理解："><a href="#个人理解：" class="headerlink" title="个人理解："></a>个人理解：</h3><p>缺乏明确的模式可以迅速将数据湖变成无法操作的数据沼泽</p>]]></content>
    
    
    
    <tags>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据湖简介</title>
    <link href="/2020/07/09/%E6%95%B0%E6%8D%AE%E6%B9%96%E7%AE%80%E4%BB%8B/"/>
    <url>/2020/07/09/%E6%95%B0%E6%8D%AE%E6%B9%96%E7%AE%80%E4%BB%8B/</url>
    
    <content type="html"><![CDATA[<h3 id="什么是数据湖？"><a href="#什么是数据湖？" class="headerlink" title="什么是数据湖？"></a>什么是数据湖？</h3><p>AWS：以<strong>任意规模</strong>将您的<strong>所有数据</strong>存储在一个<strong>集中式</strong>存储库中</p><p>允许以任意规模存储所有结构化和非结构化的数据，可以按照原样存储而无需对数据进行结构化处理，并运行不同类型的分析。</p><ul><li><p>首先要能满足导入任何数量，任意来源的实时数据，可以以原始形式入湖，从而节省定义数据结构，schema，和转换的时间。</p></li><li><p>能够存储关系和非关系数据，并通过对数据进行发现，编目，建立索引来了解数据湖中的数据。</p></li><li><p>数据湖能够允许任何角色，以各自的框架来访问分析数据，比如spark，presto sql等</p></li><li><p>能够报告历史数据，进行机器学习等能力。</p></li></ul><h3 id="数据湖-vs-数据仓库"><a href="#数据湖-vs-数据仓库" class="headerlink" title="数据湖 vs 数据仓库"></a>数据湖 vs 数据仓库</h3><ul><li><p>数据仓库是一个优化的数据库，用于分析来自事务系统和业务线应用程序产生的关系数据，存储的是大量结构化的数据。</p><p>比如hive就是通过元数据来描述Hdfs上的结构化文本数据，也就是通过事先定义数据结构和 Schema 以优化快速 SQL 查询，其中结果通常用于操作报告和分析。</p><p>数据进入数仓前会经过了ETL清理、丰富和转换，因此可以充当用户可信任的“单一信息源”。</p></li><li><p>数据湖有所不同，因为它存储来自业务线应用程序的关系数据，以及来自移动应用程序、IoT 设备和社交媒体的非关系数据。</p><p>捕获数据时，未定义数据结构或 Schema。也就是可以存储所有数据，无需ETL。</p><p>可以对数据使用不同类型的分析（如 SQL 查询、大数据分析、全文搜索、实时分析和机器学习）</p></li><li><p>也就是说数据仓库入库时需要做ETL，库里都是结构化数据，而数据湖入湖时可以保留原始格式，入湖后再定义架构，元数据，仅在分析时再进行转换。</p></li></ul><h3 id="下一代数据仓库"><a href="#下一代数据仓库" class="headerlink" title="下一代数据仓库"></a>下一代数据仓库</h3><h4 id="AWS-Lake-Formation"><a href="#AWS-Lake-Formation" class="headerlink" title="AWS Lake Formation"></a>AWS Lake Formation</h4><p>AWS 将 AWS Lake Formation 描述为一种用于决策支持和人工智能决策自动化的超级数据仓库。AWS 还特别强调，该服务旨在管理数据，“然后用户就可以选择他们的分析和机器学习服务，如 Amazon EMR for Spark、Amazon Redshift、Amazon Athena、Amazon SageMaker 和 Amazon QuickSight”。</p><h4 id="Delta-Lake"><a href="#Delta-Lake" class="headerlink" title="Delta Lake"></a>Delta Lake</h4><p>Delta Lake 位于数据中心或云平台的数据存储平台之上，聚合、清理和管理数据湖中的数据集，以便更好地为机器学习提供支持。 Delta Lake 可以支持批次数据和流式数据。也支持 ACID 事务，可以支持数百个应用程序的并发写入和读取。</p><h3 id="DLA数据湖分析"><a href="#DLA数据湖分析" class="headerlink" title="DLA数据湖分析"></a>DLA数据湖分析</h3><p>​        <a href="https://help.aliyun.com/product/70174.html?spm=a2c4g.11186623.6.540.d60ba1c0ep8iQ9" target="_blank" rel="noopener"><strong>数据湖分析</strong></a>（Data Lake Analytics，DLA）是无服务器（Serverless）化的云上交互式查询分析服务。无需ETL，就可通过此服务在云上通过标准JDBC直接对阿里云OSS、TableStore的数据轻松进行查询和分析，以及无缝集成商业分析工具。    </p><p>​        数据湖的构建如图所示：</p><p>​                <img src="https://cdn.jsdelivr.net/gh/likitik/helloworld@master/img/image-20200709164735633.png" srcset="/img/loading.gif" alt="image-20200709164735633" style="zoom:50%;" /></p><p>​        其中<strong>一键建仓</strong>支持阿里云关系型数据库RDS（Relational Database Service）或者云服务器ECS（Elastic Compute Service）自建数据库，只需在DLA控制台配置数据源和OSS目标位置，系统即可按照设定的数据同步时间自动、无缝的把数据源中的数据同步到目标数据仓库OSS中，同时在数据仓库和DLA中创建与数据源表相同的表结构，基于目标数据仓库进行数据分析，不影响数据源端的线上业务运行。</p><p>​        <strong>实时数据湖</strong>架构如下：</p><p><img src="https://cdn.jsdelivr.net/gh/likitik/helloworld@master/img/image-20200709164457572.png" srcset="/img/loading.gif" alt="image-20200709164457572"></p>]]></content>
    
    
    
    <tags>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TCP基础</title>
    <link href="/2020/07/08/TCP%E5%9F%BA%E7%A1%80/"/>
    <url>/2020/07/08/TCP%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h4 id="TCP基础"><a href="#TCP基础" class="headerlink" title="TCP基础"></a>TCP基础</h4><p>面向连接的，一对一，需要建立连接</p><p>可靠传输，全双工服务</p><p>面向字节流的，消息无边界</p><p>首部20字节，其中包括标志位（SYN，FIN，RST，ACK，URG，PSH），窗口大小</p><p>源端口，目的端口，序列号seq，应答号ack，校验和等</p><p>序列号处理包乱序，应答号确认不丢包</p><h4 id="最大连接数："><a href="#最大连接数：" class="headerlink" title="最大连接数："></a>最大连接数：</h4><p>对于客户端，每次需要绑定本地空闲端口，最大65535，实际3万多可用，由于TIME_WAIT所以其实每秒不超过500</p><p>对于服务端，受内存和socket文件描述符限制</p><h4 id="常见场景："><a href="#常见场景：" class="headerlink" title="常见场景："></a>常见场景：</h4><p>FTP，HTTP/HTTPS</p><h4 id="三次握手："><a href="#三次握手：" class="headerlink" title="三次握手："></a>三次握手：</h4><img src="https://cdn.jsdelivr.net/gh/likitik/helloworld@master/img/B703D972-AD7E-429D-BC27-5A03362584A0.png" srcset="/img/loading.gif" alt="B703D972-AD7E-429D-BC27-5A03362584A0" style="zoom:67%;" /><p>第三次可以携带数据，如http-GET</p><p>为了避免影响，初始序列号是随机的</p><p> ISN = M（时钟）+F（四元组hash）</p><p>netstat -napt</p><p>为什么需要三次握手</p><ul><li>避免历史连接，如果没有三次握手，一个旧的syn包被确认了，就代表一个历史的错误连接建立了。而有三次握手，客户端会根据历史上下文判断该ack错误，而发rst中止连接。</li><li>同步双方序列号，四次合三次的过程</li><li>避免冗余连接，syn包阻塞，会重新发，服务器端全部建立，造成冗余无效链接，浪费。</li></ul><h4 id="四次挥手："><a href="#四次挥手：" class="headerlink" title="四次挥手："></a>四次挥手：</h4><img src="https://cdn.jsdelivr.net/gh/likitik/helloworld@master/img/A046A75D-2F4D-4238-B691-ECEDC6E7B070.png" srcset="/img/loading.gif" alt="A046A75D-2F4D-4238-B691-ECEDC6E7B070" style="zoom:67%;" /><p>如果客户端最后的ACK丢失了，会触发服务端超时从而重发FIN包</p><p>收到FIN包后重发ACK给服务端，一来一回正好两个MSL（报文最大生存时间）</p><h4 id="TIME-WAIT"><a href="#TIME-WAIT" class="headerlink" title="TIME_WAIT:"></a>TIME_WAIT:</h4><ul><li><p>确保两个方向上的数据包都被丢弃了，防止被延迟的旧连接的数据包被接收</p></li><li><p>保证连接正确关闭，确保最后的ACK被服务端收到，否则，服务端会对下次发起的请求直接回复RST</p></li></ul><p>解决大量TIME_WAIT</p><ul><li><p>设置关闭tcp连接直接发送rst</p></li><li><p>允许复用time_wait中的tcp连接</p></li></ul><h4 id="如果已经建立了连接，但是客户端突然出现故障了怎么办？"><a href="#如果已经建立了连接，但是客户端突然出现故障了怎么办？" class="headerlink" title="如果已经建立了连接，但是客户端突然出现故障了怎么办？"></a>如果已经建立了连接，但是客户端突然出现故障了怎么办？</h4><p>TCP保活机制：每隔一个时间间隔，发送探测报文</p><h4 id="滑动窗口："><a href="#滑动窗口：" class="headerlink" title="滑动窗口："></a>滑动窗口：</h4><p>滑动窗口是为了解决接收方和发送方能力不匹配的问题，减少重传</p><p>tcp报文中窗口大小，表明自己的接收能力</p><h4 id="拥塞控制："><a href="#拥塞控制：" class="headerlink" title="拥塞控制："></a>拥塞控制：</h4><p>拥塞控制避免一开始大量流量进入网络，超过网络负载能力，造成延迟等待</p><ul><li><p>慢开始</p></li><li><ul><li>在TCP刚建立连接或者当网络发生拥塞超时的时候，将拥塞窗口cwnd设置成一个报文段大小，并且当cwnd&lt;=ssthresh时，指数方式增大cwnd（即每经过一个传输轮次，cwnd加倍）。</li></ul></li><li><p>拥塞避免</p></li><li><ul><li>当cwnd&gt;=sshresh时，为避免网络发生拥塞，进入拥塞避免算法，这时候以线性方式增大cwnd（即每经过一个传输轮次，cwnd只增大一个报文段）</li></ul></li><li><p>快重传</p></li><li><ul><li>是指发送方如果连续收到三个重复确认的ACK，则立即重传该报文段，而不必等待重传定时器超时后再重传。</li></ul></li><li><p>快恢复</p></li><li><ul><li>指当采用快速重传算法的时候，直接执行拥塞避免算法。这样可以提高传输效率。</li></ul></li></ul><p>Ssthresh通常设置成发送拥塞是的发送窗口的一半。必须&gt;=2.</p><h4 id="TCP粘包："><a href="#TCP粘包：" class="headerlink" title="TCP粘包："></a>TCP粘包：</h4><p>由于面向字节流，会对应用层数据组合或拆分，应用层没有定义消息边界导致接收方无法重组。</p><p>常见http头增加负载长度字段</p><h4 id="Nagle算法"><a href="#Nagle算法" class="headerlink" title="Nagle算法"></a>Nagle算法</h4><p>主要是避免发送小的数据包，要求TCP连接上最多只能有一个未被确认的小分组，在该分组的确认到达之前不能发送其他的小分组。</p><h4 id="syn攻击"><a href="#syn攻击" class="headerlink" title="syn攻击"></a>syn攻击</h4><p>syn队列到accept队列到accept()函数到应用</p><p>syn队列被占满</p><p>可以用cookie，当syn满了之后，将cookie返回给客户端，之后如果合理的ack，直接进入accept队列</p>]]></content>
    
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常用java内存分析工具</title>
    <link href="/2020/07/06/%E5%B8%B8%E7%94%A8java%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"/>
    <url>/2020/07/06/%E5%B8%B8%E7%94%A8java%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/</url>
    
    <content type="html"><![CDATA[<h3 id="java-lang-Runtime"><a href="#java-lang-Runtime" class="headerlink" title="java.lang.Runtime"></a>java.lang.Runtime</h3><p>获取运行时jvm内存消耗情况</p><pre><code class="hljs java"><span class="hljs-keyword">static</span> Runtime runtime = Runtime.getRuntime();<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">printUsedMemory</span><span class="hljs-params">()</span></span>&#123;    System.out.println(<span class="hljs-string">"Used Memory:"</span> + (runtime.totalMemory() - runtime.freeMemory()) / mb+<span class="hljs-string">"M"</span>);&#125;</code></pre><h3 id="org-apache-lucene"><a href="#org-apache-lucene" class="headerlink" title="org.apache.lucene"></a>org.apache.lucene</h3><p>获取指定对象的内存消耗情况</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.lucene<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>lucene-core<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>4.0.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><pre><code class="hljs java"><span class="hljs-comment">//计算指定对象及其引用树上的所有对象的综合大小，单位字节</span><span class="hljs-keyword">long</span> RamUsageEstimator.sizeOf(Object obj)<span class="hljs-comment">//计算指定对象本身在堆空间的大小，单位字节</span><span class="hljs-keyword">long</span> RamUsageEstimator.shallowSizeOf(Object obj)<span class="hljs-comment">//计算指定对象及其引用树上的所有对象的综合大小，返回可读的结果，如：2KB</span>String RamUsageEstimator.humanSizeOf(Object obj)</code></pre><h3 id="JVM性能调优工具"><a href="#JVM性能调优工具" class="headerlink" title="JVM性能调优工具"></a>JVM性能调优工具</h3><h4 id="jstat"><a href="#jstat" class="headerlink" title="jstat"></a>jstat</h4><blockquote><p>Java Virtual Machine statistics monitoring tool</p></blockquote><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> jstat -option</span>invalid argument countUsage: jstat -help|-options       jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]]Definitions:  &lt;option&gt;      An option reported by the -options option  &lt;vmid&gt;        Virtual Machine Identifier. A vmid takes the following form:                     &lt;lvmid&gt;[@&lt;hostname&gt;[:&lt;port&gt;]]                Where &lt;lvmid&gt; is the local vm identifier for the target                Java virtual machine, typically a process id; &lt;hostname&gt; is                the name of the host running the target Java virtual machine;                and &lt;port&gt; is the port number for the rmiregistry on the                target host. See the jvmstat documentation for a more complete                description of the Virtual Machine Identifier.  &lt;lines&gt;       Number of samples between header lines.  &lt;interval&gt;    Sampling interval. The following forms are allowed:                    &lt;n&gt;["ms"|"s"]                Where &lt;n&gt; is an integer and the suffix specifies the units as                milliseconds("ms") or seconds("s"). The default units are "ms".  &lt;count&gt;       Number of samples to take before terminating.  -J&lt;flag&gt;      Pass &lt;flag&gt; directly to the runtime system.    <span class="hljs-meta">#</span><span class="bash"> option： 参数选项</span><span class="hljs-meta">#</span><span class="bash"> -t： 可以在打印的列加上Timestamp列，用于显示系统运行的时间</span><span class="hljs-meta">#</span><span class="bash"> -h： 可以在周期性打印数据的时候，可以在指定输出多少行以后输出一次表头</span><span class="hljs-meta">#</span><span class="bash"> vmid： Virtual Machine ID（ 进程的 pid）</span><span class="hljs-meta">#</span><span class="bash"> interval： 执行每次的间隔时间，单位为毫秒</span><span class="hljs-meta">#</span><span class="bash"> count： 用于指定输出多少次记录，缺省则会一直打印</span></code></pre><p>参数选项</p><pre><code class="hljs she">&gt; jstat -options-class 显示ClassLoad的相关信息；-compiler 显示JIT编译的相关信息；-gc 显示和gc相关的堆信息；-gccapacity 　　 显示各个代的容量以及使用情况；-gcmetacapacity 显示metaspace的大小-gcnew 显示新生代信息；-gcnewcapacity 显示新生代大小和使用情况；-gcold 显示老年代和永久代的信息；-gcoldcapacity 显示老年代的大小；-gcutil　　 显示垃圾收集信息；-gccause 显示垃圾回收的相关信息（通-gcutil）,同时显示最后一次或当前正在发生的垃圾回收的诱因；-printcompilation 输出JIT编译的方法信息</code></pre><p>eg ：查看类加载情况</p><pre><code class="hljs she">jstat -class [进程号]# Loaded：加载class的数量 # Bytes：所占用空间大小 # Unloaded：未加载数量 # Bytes：未加载所占空间大小 # Time：时间</code></pre><h4 id="jmap"><a href="#jmap" class="headerlink" title="jmap"></a>jmap</h4><p> jmap用来查看堆内存使用状况，一般结合jhat使用。</p><pre><code class="hljs she">jmap [option] pidjmap [option] executable corejmap [option] [server-id@]remote-hostname-or-ip</code></pre><h3 id="开源工具Arthas"><a href="#开源工具Arthas" class="headerlink" title="开源工具Arthas"></a>开源工具Arthas</h3><p><a href="https://alibaba.github.io/arthas/quick-start.html" target="_blank" rel="noopener">Arthas是Alibaba开源的Java诊断工具</a></p><pre><code class="hljs shel">java -jar arthas-boot.jar #启动# 选择一个java进程# 输入dashboard，回车</code></pre><h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><h4 id="如何查看进程pid？"><a href="#如何查看进程pid？" class="headerlink" title="如何查看进程pid？"></a>如何查看进程pid？</h4><ol><li><p>程序中打印</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> <span class="hljs-title">getPID</span><span class="hljs-params">()</span></span>&#123;    RuntimeMXBean runtimeMXBean = ManagementFactory.getRuntimeMXBean();    <span class="hljs-keyword">return</span> Integer.parseInt(runtimeMXBean.getName().split(<span class="hljs-string">"@"</span>)[<span class="hljs-number">0</span>]);&#125;</code></pre></li><li><p>jps</p></li></ol><h4 id="如何设置java程序内存大小？"><a href="#如何设置java程序内存大小？" class="headerlink" title="如何设置java程序内存大小？"></a>如何设置java程序内存大小？</h4><pre><code class="hljs shell">-vmargs -Xms128M -Xmx512M -XX:PermSize=64M -XX:MaxPermSize=128M-vmargs 说明后面是VM的参数，所以后面的其实都是JVM的参数了-Xms128m JVM初始分配的堆内存-Xmx512m JVM最大允许分配的堆内存，按需分配-XX:PermSize=64M JVM初始分配的非堆内存-XX:MaxPermSize=128M JVM最大允许分配的非堆内存，按需分配</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>初识Hbase</title>
    <link href="/2020/07/05/%E5%88%9D%E8%AF%86Hbase/"/>
    <url>/2020/07/05/%E5%88%9D%E8%AF%86Hbase/</url>
    
    <content type="html"><![CDATA[<h1 id="Hbase"><a href="#Hbase" class="headerlink" title="Hbase"></a>Hbase</h1><p><a href="https://mp.weixin.qq.com/s/9Y4HXb4UG8Fxu2F0YXBuMQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/9Y4HXb4UG8Fxu2F0YXBuMQ</a></p><p>Hbase：<br>完全分布式，数据分片，故障自恢复<br>底层HDFS（存储计算分离）<br>扩展好，内置容错恢复和数据冗余</p><h3 id="Hbase-vs-Hive"><a href="#Hbase-vs-Hive" class="headerlink" title="Hbase vs Hive"></a>Hbase vs Hive</h3><p>hbase：hadoop database，基于hadoop的分布式nosql数据库，主要适用于海量（PB级）明细数据的随机实时查询，如交易明细，轨迹行为。</p><p>hbase是面向列的KV数据库，架构上由client，Zookeeper，HMaster，HRegion组成。</p><ul><li>ZK 集群是负责转发 Client 的请求和提供心跳机制，会让 HRegion Server 和 HRegion 注册进来，同时保存着 Rowkey 和 Region 的映射关系。</li><li>HMaster 中可以有多个待命，只有一个在活跃。</li></ul><p>Region Server即机器节点，包含多个Region，一个Region包含多个CF（Column Family）</p><p>一个Region Server中有一张HLOG，多张Table，一张Table可以有多个Region，一个Region有多个Store，一个CF是存在一个Store中的（Mem Store 、Store File）。</p><p><img src="https://cdn.jsdelivr.net/gh/likitik/helloworld@master/img/ea_hbase.png" srcset="/img/loading.gif" alt="hbase"></p><p>KEY是以Row key + CF + Column + TimeStamp 组成。</p><p>读取和写入都是先找到对应的Region Server，再找到对应的Region</p><p>先访问MemStore，再考虑磁盘的Storefile。（类似LSM）</p><p><a href="https://juejin.im/post/5c31cf486fb9a04a102f6f89" target="_blank" rel="noopener">https://juejin.im/post/5c31cf486fb9a04a102f6f89</a></p><p>通俗的说，hbase的作用类似于数据库，传统数据库管理的是集中的本地数据文件，而<strong>hbase基于hdfs实现对分布式数据文件的管理，比如增删改查</strong>。也就是说，hbase<strong>只是利用hadoop的hdfs帮助其管理数据的持久化文件（HFile）</strong>，<strong>它跟MapReduce没任何关系。</strong></p><p><strong>hbase的优势在于实时计算</strong>，所有实时数据都直接存入hbase中，客户端通过API直接访问hbase，实现实时计算。由于它使用的是nosql，或者说是列式结构，从而提高了查找性能，使其能运用于大数据场景，这是它跟MapReduce的区别。</p><p><strong>hadoop是hive和hbase的基础</strong>，hive依赖hadoop，而hbase仅依赖hadoop的hdfs模块。</p><p>hive适用于<strong>离线数据的分析</strong>，操作的是通用格式的（如通用的日志文件）、被hadoop管理的数据文件，它支持类sql，比编写MapReduce的java代码来的更加方便，它的定位是数据仓库，存储和分析历史数据。</p><p>hbase适用于<strong>实时计算</strong>，采用列式结构的nosql，操作的是自己生成的特殊格式的HFile、被hadoop管理的数据文件，它的定位是数据库，或者叫DBMS。</p><p>hive可以直接操作hdfs中的文件作为它的表的数据，也可以使用hbase数据库作为它的表。</p><p><a href="https://blog.csdn.net/JiaoZi00_/article/details/80262244" target="_blank" rel="noopener">https://blog.csdn.net/JiaoZi00_/article/details/80262244</a></p><h1 id="InnoDB-Buffer-Pool"><a href="#InnoDB-Buffer-Pool" class="headerlink" title="InnoDB Buffer Pool"></a>InnoDB Buffer Pool</h1><p><a href="https://zhuanlan.zhihu.com/p/65811829" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/65811829</a></p><h2 id="HBase场景"><a href="#HBase场景" class="headerlink" title="HBase场景"></a>HBase场景</h2><ol><li>通过ETL工具将数据源抽取到HDFS存储；</li><li>通过Hive清洗、处理和计算原始数据；</li><li>HIve清洗处理后的结果，如果是面向海量数据随机查询场景的可存入Hbase</li><li>数据应用从HBase查询数据；</li></ol><p><img src="https://intranetproxy.alipay.com/skylark/lark/0/2020/png/305680/1590997565954-81b8860c-42c5-45df-bf2a-a9c2bd470766.png#align=left&display=inline&height=270&margin=%5Bobject%20Object%5D&name=image.png&originHeight=540&originWidth=1954&size=280626&status=done&style=none&width=977" srcset="/img/loading.gif" alt="image.png"><br><img src="https://intranetproxy.alipay.com/skylark/lark/0/2020/png/305680/1590992678139-ffb730ad-a80f-42bf-87d5-95413ae0a059.png#align=left&display=inline&height=804&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1608&originWidth=3004&size=1999601&status=done&style=none&width=1502" srcset="/img/loading.gif" alt="image.png"><br><img src="https://intranetproxy.alipay.com/skylark/lark/0/2020/png/305680/1590992713244-fbd5d447-0ca9-4319-b3e0-7590ecfc7f60.png#align=left&display=inline&height=826&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1652&originWidth=3006&size=2009880&status=done&style=none&width=1503" srcset="/img/loading.gif" alt="image.png"></p><p><img src="https://intranetproxy.alipay.com/skylark/lark/0/2020/png/305680/1590992731407-ee295d1c-a53f-4e86-9507-18463cab9a4a.png#align=left&display=inline&height=849&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1698&originWidth=2850&size=2093493&status=done&style=none&width=1425" srcset="/img/loading.gif" alt="image.png"></p><p><img src="https://intranetproxy.alipay.com/skylark/lark/0/2020/png/305680/1590992805830-2c8194e8-9f02-48b6-8bff-f3a0aa9c0b05.png#align=left&display=inline&height=822&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1644&originWidth=3014&size=1670759&status=done&style=none&width=1507" srcset="/img/loading.gif" alt="image.png"></p>]]></content>
    
    
    
    <tags>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>java设计规则引擎</title>
    <link href="/2020/07/05/java%E8%AE%BE%E8%AE%A1%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E/"/>
    <url>/2020/07/05/java%E8%AE%BE%E8%AE%A1%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E/</url>
    
    <content type="html"><![CDATA[<blockquote><p>用java设计一个规则引擎，要求首先抽象独立的规则，实现可插拔自定义的有序规则集</p><p>例如：结果有效的条件为满足顺序满足规则1，2，3</p><p>设计思路：将枚举与匿名内部类一起使用</p></blockquote><p>规则接口</p><pre><code class="hljs jade">public interface Rule &#123;    public Object apply(Object object);&#125;</code></pre><p>具体规则</p><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">enum</span>  ConcreteRule &#123;    RULE_ONE(<span class="hljs-keyword">new</span> Rule()&#123;        <span class="hljs-function"><span class="hljs-keyword">public</span> Object <span class="hljs-title">apply</span><span class="hljs-params">(Object object)</span> </span>&#123;            System.out.println(<span class="hljs-string">"RULE ONE"</span>);            <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;        &#125;    &#125;),    RULE_TWO(<span class="hljs-keyword">new</span> Rule() &#123;        <span class="hljs-function"><span class="hljs-keyword">public</span> Object <span class="hljs-title">apply</span><span class="hljs-params">(Object object)</span> </span>&#123;            System.out.println(<span class="hljs-string">"RULE TWO"</span>);            <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;        &#125;    &#125;),    RULE_THREE(<span class="hljs-keyword">new</span> Rule() &#123;        <span class="hljs-function"><span class="hljs-keyword">public</span> Object <span class="hljs-title">apply</span><span class="hljs-params">(Object object)</span> </span>&#123;            System.out.println(<span class="hljs-string">"RULE THREE"</span>);            <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;        &#125;    &#125;)    ;    <span class="hljs-keyword">private</span> Rule rule;    ConcreteRule(Rule rule) &#123;        <span class="hljs-keyword">this</span>.rule = rule;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> Object <span class="hljs-title">apply</span><span class="hljs-params">(Object object)</span></span>&#123;        <span class="hljs-keyword">return</span> rule.apply(object);    &#125;&#125;</code></pre><p>规则集</p><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RuleSet</span> </span>&#123;    <span class="hljs-keyword">private</span> List&lt;ConcreteRule&gt; rules;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">RuleSet</span><span class="hljs-params">()</span></span>&#123;        rules = <span class="hljs-keyword">new</span> ArrayList&lt;ConcreteRule&gt;();    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">add</span><span class="hljs-params">(ConcreteRule rule)</span></span>&#123;        rules.add(rule);    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> Object <span class="hljs-title">apply</span><span class="hljs-params">(Object object)</span></span>&#123;        <span class="hljs-keyword">for</span> (ConcreteRule rule : rules)&#123;            rule.apply(object);        &#125;        System.out.println(<span class="hljs-string">"rules apply over!"</span>);        <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;    &#125;&#125;</code></pre><p>规则工厂</p><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RuleSets</span> </span>&#123;    <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-title">RuleSets</span><span class="hljs-params">()</span></span>&#123;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> RuleSet <span class="hljs-title">isXXX</span><span class="hljs-params">()</span></span>&#123;        RuleSet ruleSet = <span class="hljs-keyword">new</span> RuleSet();        ruleSet.add(ConcreteRule.RULE_ONE);        ruleSet.add(ConcreteRule.RULE_TWO);        ruleSet.add(ConcreteRule.RULE_THREE);        <span class="hljs-keyword">return</span> ruleSet;    &#125;&#125;</code></pre><p>Main函数</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;  Object a = <span class="hljs-keyword">new</span> Object();  RuleSet ruleSet = RuleSets.isXXX();  ruleSet.apply(a);&#125;</code></pre><ul><li>TODO：可以考虑lambda表达式简化构造</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>java设计模式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Epoll</title>
    <link href="/2020/07/05/Epoll/"/>
    <url>/2020/07/05/Epoll/</url>
    
    <content type="html"><![CDATA[<h4 id="Select-Epoll"><a href="#Select-Epoll" class="headerlink" title="Select,Epoll"></a>Select,Epoll</h4><ul><li><p>一次ＩＯ访问，需要先将数据拷贝进内核缓冲区，再拷贝到应用程序地址空间。</p></li><li><p>阻塞</p></li><li><ul><li>进程发起read请求，等待状态下进程主动阻塞</li></ul></li><li><p>非阻塞</p></li><li><ul><li>进程不断的主动询问内核，返回ｅｒｒｏｒ</li></ul></li><li><p>I/O多路复用</p></li><li><ul><li>单个process就可以同时处理多个网络连接的IO，select，poll，epoll这个function会不断的轮询所负责的所有socket，，当某个socket有数据到达了，就通知用户进程。</li></ul></li><li><p>如何知道接收了数据：</p></li><li><ul><li>网卡把数据写入内存后，向cpu发出一个中断信号，操作系统就知道有新数据来了</li></ul></li><li><p>阻塞为什么不占用cpu资源</p></li><li><ul><li>进程阻塞，进入等待队列（从cpu轮询的工作队列中移出），socket创建一个由文件系统管理的对象，这个socket对象包含了发送接收缓冲区以及等待队列的成员，当网卡通知cpu有数据到达，cpu执行中断程序，把网络数据写入socket接收缓冲区，再唤醒等待队列的进程</li></ul></li><li><p>如何同时监视多个socket的数据？</p></li><li><p>select：</p></li><li><ul><li><p>如果程序A同时监视多个socket，那么就把该进程分别加入这多个socket的等待队列中，这样任何一个socket收到数据，都会唤醒进程，但之后程序需要遍历socket列表，才能得到具体是哪个socket就绪了。</p></li><li><p>缺点：</p></li><li><ul><li>每次调用需要把进程加入所有监视的socket等待队列中，每次唤醒也需要遍历寻找和移除，因此每次都要将整个FDS列表传给内核，开销很大。</li><li>最大监视数1024</li></ul></li></ul></li><li><p>epoll：</p></li><li><ul><li><p>功能分离，用epoll_ctl维护等待队列，用epoll_wait阻塞进程</p></li><li><p>epoll_create:内核创建一个event poll对象，也是文件系统一员，有自己的等待队列</p></li><li><ul><li>就绪列表rdlist，保存所有就绪的socket，避免遍历（双向链表实现）</li><li>等待队列，连进程</li><li>索引结构，保存socket，用红黑树</li></ul></li><li><p>监视过程变为把eventpoll对象添加到每个socket的等待队列中，收到数据后，中断程序要做的是操作eventpoll对象，给rdlist添加socket引用，所以当epoll_wait的时候，如果rdlist不为空直接返回</p></li></ul></li><li><p>水平触发与边缘触发</p></li><li><ul><li>水平触发：每次文件描述符就绪后，一遍一次IO没有执行完，下次epoll_wait时还是就绪态，还可以继续执行。只要缓冲区不空就可以读，不满就可以写，如果没有一次性读写完，下次还会提示就绪并读写。这样系统中如果有很多并不需要读写但是就绪的文件描述符，每次都要返回。降低了效率。</li><li>边缘触发：如果一次没有执行完，直到下次IO可读写事件发生前都不会再有通知，也就是只要0变1的上升沿才会触发，丢失了剩余的数据。在发生文件描述符就绪时，采用非阻塞的方式尽可能多的进行IO。</li></ul></li></ul><ul><li><p>高并发场景下，对消息的读取和分割可能和epoll_wait在不同的线程中，这时候如果选择LT，那么在读完数据前，epoll_wait会不停的无谓醒来。</p></li><li><p>饥饿现象：</p></li><li><ul><li>在边缘触发条件下，存在某个就绪的文件描述符上有大量的输入，会出现饥饿现象</li></ul></li></ul><h4 id="用epoll实现定时器"><a href="#用epoll实现定时器" class="headerlink" title="用epoll实现定时器"></a>用epoll实现定时器</h4><h4 id="用epoll处理signal"><a href="#用epoll处理signal" class="headerlink" title="用epoll处理signal"></a>用epoll处理signal</h4><p>将signal转换为对一个文件描述符的读写，初始化一个管道，一端read，一端write，其中read添加到epoll中，这样当信号来的时候，将信号写入wirte端，read端的文件描述符上的read事件被触发，epoll_wait就返回了</p>]]></content>
    
    
    
    <tags>
      
      <tag>操作系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>进程与线程</title>
    <link href="/2020/07/05/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/"/>
    <url>/2020/07/05/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<ul><li><p>进程是操作系统分配资源的最小单位，是程序的实体，操作系统运行一个程序，那这个程序就是一个进程，每个进程有自己的pid进程号。操作系统会为进程分配一块内存。</p></li><li><p>而线程包含在进程之中，一个进程可以并发多个线程，但这里的并发是在cpu时间片上的串行执行，同一个进程中的线程共享进程包括内存的所有资源，而每个线程只需要分配自己的一个程序计数器，栈，寄存器这些东西。在线程上的切换是由内核根据这些完成的。</p></li><li><p>在进程中可以创建fork一个子进程，调用系统的clone操作，在内核中创建出一个task对象，并返回子进程号，区别在于是否拷贝内存，当然拷贝的话现在的操作系统也是拷贝索引。</p></li><li><p>进程控制块PCB（数据结构）</p></li><li><ul><li><p>pid</p></li><li><p>user</p></li><li><p>ppid</p></li><li><p>状态保存区，栈，pc，寄存器</p></li><li><p>控制信息</p></li><li><ul><li>状态</li><li>通信信息</li><li>所用资源</li><li>进程链</li></ul></li></ul></li><li><p>进程 = 资源平台+执行线程</p></li><li><p>线程能够减少并发执行的时间和空间，比进程创建和结束的时间短，切换时间短，可直接进行不通过内核的通信</p></li><li><p>CPU对进程的管理</p></li><li><p>进程状态</p></li><li><ul><li><p>创建</p></li><li><ul><li><p>为子进程分配内存fork</p></li><li><p>复制父进程内存和cpu寄存器到子进程</p></li><li><p>exec加载并执行，使得上一步对父进程的复制没有作用了</p></li><li><ul><li>可以通过vfork优化，分配内存后直接exec</li><li>cow写时复制，利用虚存管理，只复制页表，共享的读，只有写时复制双份</li></ul></li></ul></li><li><p>就绪</p></li><li><ul><li>阻塞态被唤醒进入就绪态</li><li>运行态遇到时间片调度，进入就绪态</li><li>中断产生，运行态进入就绪态</li></ul></li><li><p>运行</p></li><li><p>阻塞</p></li><li><ul><li>进程自我阻塞，select，sleep等</li></ul></li><li><p>结束（僵尸）</p></li><li><ul><li>wait父进程等待子进程结束，帮助销毁回收内核中的僵尸PCB数据</li><li>exit只能释放自己的内存，关闭文件连接，释放内存，检查父进程是否存活，清理僵尸进程</li></ul></li></ul></li><li><p>cpu调度</p></li><li><ul><li><p>从就绪队列中选择一个进程/线程，进入运行态</p></li><li><p>上下文切换</p></li><li><ul><li>切换当前cpu任务，从一个进程/线程进入下一个</li><li>保存当前pcb/tcb中的上下文cpu状态</li><li>读取下一个进程/线程的上下文</li></ul></li><li><p>原则</p></li><li><ul><li>cpu使用率，吞吐量（单位时间总完成），周转时间，等待时间，响应时间，公平</li></ul></li><li><p>策略</p></li><li><ul><li><p>FCFS先来先服务</p></li><li><p>短进程优先</p></li><li><p>最高响应比优先R = （等待+执行）/等待</p></li><li><p>轮询（定义合适的时间片，减少上下文切换开销）</p></li><li><p>多级反馈队列</p></li><li><ul><li>多级，高优先级队列先执行</li><li>各个队列内部可以选择不同的策略</li><li>反馈，任务随着运行时间动态优先级下降和上升</li></ul></li><li><p>公平共享调度，面对多用户</p></li></ul></li><li><p>优先级反转</p></li><li><ul><li>ABC优先级任务，C占用了x资源，A等待x资源即等待C的释放，但B优先级高于C，所以C需要等待B，导致A被低优先级B影响</li><li>优先级继承，或设置资源优先级</li></ul></li></ul></li><li><p>linux调度器</p></li><li><ul><li><p>O（n）</p></li><li><ul><li>就绪队列遍历问题</li><li>多核cpu扩展性问题，通过自旋锁满足多个cpu对队列的并发访问</li><li>cpu空转问题，全部进程时间片被耗尽后需要重新计算时间片</li><li>一个进程会在多个cpu上跳来跳去</li><li>实时调度性能一般</li></ul></li><li><p>O（1）</p></li><li><ul><li>每个CPU都有一个runable队列，把大锁变成小锁</li><li>优先级反馈队列</li><li>负载层</li><li>抢占式内核</li></ul></li><li><p>CFS</p></li><li><ul><li>CFS调度器的公平就是保证所有的可运行状态的进程按照权重分配其CPU资源</li><li>红黑树，虚拟时间轴</li></ul></li></ul></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>操作系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
