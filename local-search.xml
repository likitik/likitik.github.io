<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>数据湖简介</title>
    <link href="/2020/07/09/%E6%95%B0%E6%8D%AE%E6%B9%96%E7%AE%80%E4%BB%8B/"/>
    <url>/2020/07/09/%E6%95%B0%E6%8D%AE%E6%B9%96%E7%AE%80%E4%BB%8B/</url>
    
    <content type="html"><![CDATA[<h3 id="什么是数据湖？"><a href="#什么是数据湖？" class="headerlink" title="什么是数据湖？"></a>什么是数据湖？</h3><p>AWS：以<strong>任意规模</strong>将您的<strong>所有数据</strong>存储在一个<strong>集中式</strong>存储库中</p><p>允许以任意规模存储所有结构化和非结构化的数据，可以按照原样存储而无需对数据进行结构化处理，并运行不同类型的分析。</p><ul><li><p>首先要能满足导入任何数量，任意来源的实时数据，可以以原始形式入湖，从而节省定义数据结构，schema，和转换的时间。</p></li><li><p>能够存储关系和非关系数据，并通过对数据进行发现，编目，建立索引来了解数据湖中的数据。</p></li><li><p>数据湖能够允许任何角色，以各自的框架来访问分析数据，比如spark，presto sql等</p></li><li><p>能够报告历史数据，进行机器学习等能力。</p></li></ul><h3 id="数据湖-vs-数据仓库"><a href="#数据湖-vs-数据仓库" class="headerlink" title="数据湖 vs 数据仓库"></a>数据湖 vs 数据仓库</h3><ul><li><p>数据仓库是一个优化的数据库，用于分析来自事务系统和业务线应用程序产生的关系数据，存储的是大量结构化的数据。</p><p>比如hive就是通过元数据来描述Hdfs上的结构化文本数据，也就是通过事先定义数据结构和 Schema 以优化快速 SQL 查询，其中结果通常用于操作报告和分析。</p><p>数据进入数仓前会经过了ETL清理、丰富和转换，因此可以充当用户可信任的“单一信息源”。</p></li><li><p>数据湖有所不同，因为它存储来自业务线应用程序的关系数据，以及来自移动应用程序、IoT 设备和社交媒体的非关系数据。</p><p>捕获数据时，未定义数据结构或 Schema。也就是可以存储所有数据，无需ETL。</p><p>可以对数据使用不同类型的分析（如 SQL 查询、大数据分析、全文搜索、实时分析和机器学习）</p></li><li><p>也就是说数据仓库入库时需要做ETL，库里都是结构化数据，而数据湖入湖时可以保留原始格式，入湖后再定义架构，元数据，仅在分析时再进行转换。</p></li></ul><h3 id="下一代数据仓库"><a href="#下一代数据仓库" class="headerlink" title="下一代数据仓库"></a>下一代数据仓库</h3><h4 id="AWS-Lake-Formation"><a href="#AWS-Lake-Formation" class="headerlink" title="AWS Lake Formation"></a>AWS Lake Formation</h4><p>AWS 将 AWS Lake Formation 描述为一种用于决策支持和人工智能决策自动化的超级数据仓库。AWS 还特别强调，该服务旨在管理数据，“然后用户就可以选择他们的分析和机器学习服务，如 Amazon EMR for Spark、Amazon Redshift、Amazon Athena、Amazon SageMaker 和 Amazon QuickSight”。</p><h4 id="Delta-Lake"><a href="#Delta-Lake" class="headerlink" title="Delta Lake"></a>Delta Lake</h4><p>Delta Lake 位于数据中心或云平台的数据存储平台之上，聚合、清理和管理数据湖中的数据集，以便更好地为机器学习提供支持。 Delta Lake 可以支持批次数据和流式数据。也支持 ACID 事务，可以支持数百个应用程序的并发写入和读取。</p><h3 id="DLA数据湖分析"><a href="#DLA数据湖分析" class="headerlink" title="DLA数据湖分析"></a>DLA数据湖分析</h3><p>​        <a href="https://help.aliyun.com/product/70174.html?spm=a2c4g.11186623.6.540.d60ba1c0ep8iQ9" target="_blank" rel="noopener"><strong>数据湖分析</strong></a>（Data Lake Analytics，DLA）是无服务器（Serverless）化的云上交互式查询分析服务。无需ETL，就可通过此服务在云上通过标准JDBC直接对阿里云OSS、TableStore的数据轻松进行查询和分析，以及无缝集成商业分析工具。    </p><p>​        数据湖的构建如图所示：</p><p>​                <img src="https://cdn.jsdelivr.net/gh/likitik/helloworld@master/img/image-20200709164735633.png" srcset="/img/loading.gif" alt="image-20200709164735633" style="zoom:50%;" /></p><p>​        其中<strong>一键建仓</strong>支持阿里云关系型数据库RDS（Relational Database Service）或者云服务器ECS（Elastic Compute Service）自建数据库，只需在DLA控制台配置数据源和OSS目标位置，系统即可按照设定的数据同步时间自动、无缝的把数据源中的数据同步到目标数据仓库OSS中，同时在数据仓库和DLA中创建与数据源表相同的表结构，基于目标数据仓库进行数据分析，不影响数据源端的线上业务运行。</p><p>​        <strong>实时数据湖</strong>架构如下：</p><p><img src="https://cdn.jsdelivr.net/gh/likitik/helloworld@master/img/image-20200709164457572.png" srcset="/img/loading.gif" alt="image-20200709164457572"></p>]]></content>
    
    
    
    <tags>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TCP基础</title>
    <link href="/2020/07/08/TCP%E5%9F%BA%E7%A1%80/"/>
    <url>/2020/07/08/TCP%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h4 id="TCP基础"><a href="#TCP基础" class="headerlink" title="TCP基础"></a>TCP基础</h4><p>面向连接的，一对一，需要建立连接</p><p>可靠传输，全双工服务</p><p>面向字节流的，消息无边界</p><p>首部20字节，其中包括标志位（SYN，FIN，RST，ACK，URG，PSH），窗口大小</p><p>源端口，目的端口，序列号seq，应答号ack，校验和等</p><p>序列号处理包乱序，应答号确认不丢包</p><h4 id="最大连接数："><a href="#最大连接数：" class="headerlink" title="最大连接数："></a>最大连接数：</h4><p>对于客户端，每次需要绑定本地空闲端口，最大65535，实际3万多可用，由于TIME_WAIT所以其实每秒不超过500</p><p>对于服务端，受内存和socket文件描述符限制</p><h4 id="常见场景："><a href="#常见场景：" class="headerlink" title="常见场景："></a>常见场景：</h4><p>FTP，HTTP/HTTPS</p><h4 id="三次握手："><a href="#三次握手：" class="headerlink" title="三次握手："></a>三次握手：</h4><img src="https://cdn.jsdelivr.net/gh/likitik/helloworld@master/img/B703D972-AD7E-429D-BC27-5A03362584A0.png" srcset="/img/loading.gif" alt="B703D972-AD7E-429D-BC27-5A03362584A0" style="zoom:67%;" /><p>第三次可以携带数据，如http-GET</p><p>为了避免影响，初始序列号是随机的</p><p> ISN = M（时钟）+F（四元组hash）</p><p>netstat -napt</p><p>为什么需要三次握手</p><ul><li>避免历史连接，如果没有三次握手，一个旧的syn包被确认了，就代表一个历史的错误连接建立了。而有三次握手，客户端会根据历史上下文判断该ack错误，而发rst中止连接。</li><li>同步双方序列号，四次合三次的过程</li><li>避免冗余连接，syn包阻塞，会重新发，服务器端全部建立，造成冗余无效链接，浪费。</li></ul><h4 id="四次挥手："><a href="#四次挥手：" class="headerlink" title="四次挥手："></a>四次挥手：</h4><img src="https://cdn.jsdelivr.net/gh/likitik/helloworld@master/img/A046A75D-2F4D-4238-B691-ECEDC6E7B070.png" srcset="/img/loading.gif" alt="A046A75D-2F4D-4238-B691-ECEDC6E7B070" style="zoom:67%;" /><p>如果客户端最后的ACK丢失了，会触发服务端超时从而重发FIN包</p><p>收到FIN包后重发ACK给服务端，一来一回正好两个MSL（报文最大生存时间）</p><h4 id="TIME-WAIT"><a href="#TIME-WAIT" class="headerlink" title="TIME_WAIT:"></a>TIME_WAIT:</h4><ul><li><p>确保两个方向上的数据包都被丢弃了，防止被延迟的旧连接的数据包被接收</p></li><li><p>保证连接正确关闭，确保最后的ACK被服务端收到，否则，服务端会对下次发起的请求直接回复RST</p></li></ul><p>解决大量TIME_WAIT</p><ul><li><p>设置关闭tcp连接直接发送rst</p></li><li><p>允许复用time_wait中的tcp连接</p></li></ul><h4 id="如果已经建立了连接，但是客户端突然出现故障了怎么办？"><a href="#如果已经建立了连接，但是客户端突然出现故障了怎么办？" class="headerlink" title="如果已经建立了连接，但是客户端突然出现故障了怎么办？"></a>如果已经建立了连接，但是客户端突然出现故障了怎么办？</h4><p>TCP保活机制：每隔一个时间间隔，发送探测报文</p><h4 id="滑动窗口："><a href="#滑动窗口：" class="headerlink" title="滑动窗口："></a>滑动窗口：</h4><p>滑动窗口是为了解决接收方和发送方能力不匹配的问题，减少重传</p><p>tcp报文中窗口大小，表明自己的接收能力</p><h4 id="拥塞控制："><a href="#拥塞控制：" class="headerlink" title="拥塞控制："></a>拥塞控制：</h4><p>拥塞控制避免一开始大量流量进入网络，超过网络负载能力，造成延迟等待</p><ul><li><p>慢开始</p></li><li><ul><li>在TCP刚建立连接或者当网络发生拥塞超时的时候，将拥塞窗口cwnd设置成一个报文段大小，并且当cwnd&lt;=ssthresh时，指数方式增大cwnd（即每经过一个传输轮次，cwnd加倍）。</li></ul></li><li><p>拥塞避免</p></li><li><ul><li>当cwnd&gt;=sshresh时，为避免网络发生拥塞，进入拥塞避免算法，这时候以线性方式增大cwnd（即每经过一个传输轮次，cwnd只增大一个报文段）</li></ul></li><li><p>快重传</p></li><li><ul><li>是指发送方如果连续收到三个重复确认的ACK，则立即重传该报文段，而不必等待重传定时器超时后再重传。</li></ul></li><li><p>快恢复</p></li><li><ul><li>指当采用快速重传算法的时候，直接执行拥塞避免算法。这样可以提高传输效率。</li></ul></li></ul><p>Ssthresh通常设置成发送拥塞是的发送窗口的一半。必须&gt;=2.</p><h4 id="TCP粘包："><a href="#TCP粘包：" class="headerlink" title="TCP粘包："></a>TCP粘包：</h4><p>由于面向字节流，会对应用层数据组合或拆分，应用层没有定义消息边界导致接收方无法重组。</p><p>常见http头增加负载长度字段</p><h4 id="Nagle算法"><a href="#Nagle算法" class="headerlink" title="Nagle算法"></a>Nagle算法</h4><p>主要是避免发送小的数据包，要求TCP连接上最多只能有一个未被确认的小分组，在该分组的确认到达之前不能发送其他的小分组。</p><h4 id="syn攻击"><a href="#syn攻击" class="headerlink" title="syn攻击"></a>syn攻击</h4><p>syn队列到accept队列到accept()函数到应用</p><p>syn队列被占满</p><p>可以用cookie，当syn满了之后，将cookie返回给客户端，之后如果合理的ack，直接进入accept队列</p>]]></content>
    
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常用java内存分析工具</title>
    <link href="/2020/07/06/%E5%B8%B8%E7%94%A8java%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"/>
    <url>/2020/07/06/%E5%B8%B8%E7%94%A8java%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/</url>
    
    <content type="html"><![CDATA[<h3 id="java-lang-Runtime"><a href="#java-lang-Runtime" class="headerlink" title="java.lang.Runtime"></a>java.lang.Runtime</h3><p>获取运行时jvm内存消耗情况</p><pre><code class="hljs java"><span class="hljs-keyword">static</span> Runtime runtime = Runtime.getRuntime();<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">printUsedMemory</span><span class="hljs-params">()</span></span>&#123;    System.out.println(<span class="hljs-string">"Used Memory:"</span> + (runtime.totalMemory() - runtime.freeMemory()) / mb+<span class="hljs-string">"M"</span>);&#125;</code></pre><h3 id="org-apache-lucene"><a href="#org-apache-lucene" class="headerlink" title="org.apache.lucene"></a>org.apache.lucene</h3><p>获取指定对象的内存消耗情况</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.lucene<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>lucene-core<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>4.0.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><pre><code class="hljs java"><span class="hljs-comment">//计算指定对象及其引用树上的所有对象的综合大小，单位字节</span><span class="hljs-keyword">long</span> RamUsageEstimator.sizeOf(Object obj)<span class="hljs-comment">//计算指定对象本身在堆空间的大小，单位字节</span><span class="hljs-keyword">long</span> RamUsageEstimator.shallowSizeOf(Object obj)<span class="hljs-comment">//计算指定对象及其引用树上的所有对象的综合大小，返回可读的结果，如：2KB</span>String RamUsageEstimator.humanSizeOf(Object obj)</code></pre><h3 id="JVM性能调优工具"><a href="#JVM性能调优工具" class="headerlink" title="JVM性能调优工具"></a>JVM性能调优工具</h3><h4 id="jstat"><a href="#jstat" class="headerlink" title="jstat"></a>jstat</h4><blockquote><p>Java Virtual Machine statistics monitoring tool</p></blockquote><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash"> jstat -option</span>invalid argument countUsage: jstat -help|-options       jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]]Definitions:  &lt;option&gt;      An option reported by the -options option  &lt;vmid&gt;        Virtual Machine Identifier. A vmid takes the following form:                     &lt;lvmid&gt;[@&lt;hostname&gt;[:&lt;port&gt;]]                Where &lt;lvmid&gt; is the local vm identifier for the target                Java virtual machine, typically a process id; &lt;hostname&gt; is                the name of the host running the target Java virtual machine;                and &lt;port&gt; is the port number for the rmiregistry on the                target host. See the jvmstat documentation for a more complete                description of the Virtual Machine Identifier.  &lt;lines&gt;       Number of samples between header lines.  &lt;interval&gt;    Sampling interval. The following forms are allowed:                    &lt;n&gt;["ms"|"s"]                Where &lt;n&gt; is an integer and the suffix specifies the units as                milliseconds("ms") or seconds("s"). The default units are "ms".  &lt;count&gt;       Number of samples to take before terminating.  -J&lt;flag&gt;      Pass &lt;flag&gt; directly to the runtime system.    <span class="hljs-meta">#</span><span class="bash"> option： 参数选项</span><span class="hljs-meta">#</span><span class="bash"> -t： 可以在打印的列加上Timestamp列，用于显示系统运行的时间</span><span class="hljs-meta">#</span><span class="bash"> -h： 可以在周期性打印数据的时候，可以在指定输出多少行以后输出一次表头</span><span class="hljs-meta">#</span><span class="bash"> vmid： Virtual Machine ID（ 进程的 pid）</span><span class="hljs-meta">#</span><span class="bash"> interval： 执行每次的间隔时间，单位为毫秒</span><span class="hljs-meta">#</span><span class="bash"> count： 用于指定输出多少次记录，缺省则会一直打印</span></code></pre><p>参数选项</p><pre><code class="hljs she">&gt; jstat -options-class 显示ClassLoad的相关信息；-compiler 显示JIT编译的相关信息；-gc 显示和gc相关的堆信息；-gccapacity 　　 显示各个代的容量以及使用情况；-gcmetacapacity 显示metaspace的大小-gcnew 显示新生代信息；-gcnewcapacity 显示新生代大小和使用情况；-gcold 显示老年代和永久代的信息；-gcoldcapacity 显示老年代的大小；-gcutil　　 显示垃圾收集信息；-gccause 显示垃圾回收的相关信息（通-gcutil）,同时显示最后一次或当前正在发生的垃圾回收的诱因；-printcompilation 输出JIT编译的方法信息</code></pre><p>eg ：查看类加载情况</p><pre><code class="hljs she">jstat -class [进程号]# Loaded：加载class的数量 # Bytes：所占用空间大小 # Unloaded：未加载数量 # Bytes：未加载所占空间大小 # Time：时间</code></pre><h4 id="jmap"><a href="#jmap" class="headerlink" title="jmap"></a>jmap</h4><p> jmap用来查看堆内存使用状况，一般结合jhat使用。</p><pre><code class="hljs she">jmap [option] pidjmap [option] executable corejmap [option] [server-id@]remote-hostname-or-ip</code></pre><h3 id="开源工具Arthas"><a href="#开源工具Arthas" class="headerlink" title="开源工具Arthas"></a>开源工具Arthas</h3><p><a href="https://alibaba.github.io/arthas/quick-start.html" target="_blank" rel="noopener">Arthas是Alibaba开源的Java诊断工具</a></p><pre><code class="hljs shel">java -jar arthas-boot.jar #启动# 选择一个java进程# 输入dashboard，回车</code></pre><h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><h4 id="如何查看进程pid？"><a href="#如何查看进程pid？" class="headerlink" title="如何查看进程pid？"></a>如何查看进程pid？</h4><ol><li><p>程序中打印</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> <span class="hljs-title">getPID</span><span class="hljs-params">()</span></span>&#123;    RuntimeMXBean runtimeMXBean = ManagementFactory.getRuntimeMXBean();    <span class="hljs-keyword">return</span> Integer.parseInt(runtimeMXBean.getName().split(<span class="hljs-string">"@"</span>)[<span class="hljs-number">0</span>]);&#125;</code></pre></li><li><p>jps</p></li></ol><h4 id="如何设置java程序内存大小？"><a href="#如何设置java程序内存大小？" class="headerlink" title="如何设置java程序内存大小？"></a>如何设置java程序内存大小？</h4><pre><code class="hljs shell">-vmargs -Xms128M -Xmx512M -XX:PermSize=64M -XX:MaxPermSize=128M-vmargs 说明后面是VM的参数，所以后面的其实都是JVM的参数了-Xms128m JVM初始分配的堆内存-Xmx512m JVM最大允许分配的堆内存，按需分配-XX:PermSize=64M JVM初始分配的非堆内存-XX:MaxPermSize=128M JVM最大允许分配的非堆内存，按需分配</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>初识Hbase</title>
    <link href="/2020/07/05/%E5%88%9D%E8%AF%86Hbase/"/>
    <url>/2020/07/05/%E5%88%9D%E8%AF%86Hbase/</url>
    
    <content type="html"><![CDATA[<h1 id="Hbase"><a href="#Hbase" class="headerlink" title="Hbase"></a>Hbase</h1><p><a href="https://mp.weixin.qq.com/s/9Y4HXb4UG8Fxu2F0YXBuMQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/9Y4HXb4UG8Fxu2F0YXBuMQ</a></p><p>Hbase：<br>完全分布式，数据分片，故障自恢复<br>底层HDFS（存储计算分离）<br>扩展好，内置容错恢复和数据冗余</p><h3 id="Hbase-vs-Hive"><a href="#Hbase-vs-Hive" class="headerlink" title="Hbase vs Hive"></a>Hbase vs Hive</h3><p>hbase：hadoop database，基于hadoop的分布式nosql数据库，主要适用于海量（PB级）明细数据的随机实时查询，如交易明细，轨迹行为。</p><p>hbase是面向列的KV数据库，架构上由client，Zookeeper，HMaster，HRegion组成。</p><ul><li>ZK 集群是负责转发 Client 的请求和提供心跳机制，会让 HRegion Server 和 HRegion 注册进来，同时保存着 Rowkey 和 Region 的映射关系。</li><li>HMaster 中可以有多个待命，只有一个在活跃。</li></ul><p>Region Server即机器节点，包含多个Region，一个Region包含多个CF（Column Family）</p><p>一个Region Server中有一张HLOG，多张Table，一张Table可以有多个Region，一个Region有多个Store，一个CF是存在一个Store中的（Mem Store 、Store File）。</p><p><img src="https://cdn.jsdelivr.net/gh/likitik/helloworld@master/img/ea_hbase.png" srcset="/img/loading.gif" alt="hbase"></p><p>KEY是以Row key + CF + Column + TimeStamp 组成。</p><p>读取和写入都是先找到对应的Region Server，再找到对应的Region</p><p>先访问MemStore，再考虑磁盘的Storefile。（类似LSM）</p><p><a href="https://juejin.im/post/5c31cf486fb9a04a102f6f89" target="_blank" rel="noopener">https://juejin.im/post/5c31cf486fb9a04a102f6f89</a></p><p>通俗的说，hbase的作用类似于数据库，传统数据库管理的是集中的本地数据文件，而<strong>hbase基于hdfs实现对分布式数据文件的管理，比如增删改查</strong>。也就是说，hbase<strong>只是利用hadoop的hdfs帮助其管理数据的持久化文件（HFile）</strong>，<strong>它跟MapReduce没任何关系。</strong></p><p><strong>hbase的优势在于实时计算</strong>，所有实时数据都直接存入hbase中，客户端通过API直接访问hbase，实现实时计算。由于它使用的是nosql，或者说是列式结构，从而提高了查找性能，使其能运用于大数据场景，这是它跟MapReduce的区别。</p><p><strong>hadoop是hive和hbase的基础</strong>，hive依赖hadoop，而hbase仅依赖hadoop的hdfs模块。</p><p>hive适用于<strong>离线数据的分析</strong>，操作的是通用格式的（如通用的日志文件）、被hadoop管理的数据文件，它支持类sql，比编写MapReduce的java代码来的更加方便，它的定位是数据仓库，存储和分析历史数据。</p><p>hbase适用于<strong>实时计算</strong>，采用列式结构的nosql，操作的是自己生成的特殊格式的HFile、被hadoop管理的数据文件，它的定位是数据库，或者叫DBMS。</p><p>hive可以直接操作hdfs中的文件作为它的表的数据，也可以使用hbase数据库作为它的表。</p><p><a href="https://blog.csdn.net/JiaoZi00_/article/details/80262244" target="_blank" rel="noopener">https://blog.csdn.net/JiaoZi00_/article/details/80262244</a></p><h1 id="InnoDB-Buffer-Pool"><a href="#InnoDB-Buffer-Pool" class="headerlink" title="InnoDB Buffer Pool"></a>InnoDB Buffer Pool</h1><p><a href="https://zhuanlan.zhihu.com/p/65811829" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/65811829</a></p><h2 id="HBase场景"><a href="#HBase场景" class="headerlink" title="HBase场景"></a>HBase场景</h2><ol><li>通过ETL工具将数据源抽取到HDFS存储；</li><li>通过Hive清洗、处理和计算原始数据；</li><li>HIve清洗处理后的结果，如果是面向海量数据随机查询场景的可存入Hbase</li><li>数据应用从HBase查询数据；</li></ol><p><img src="https://intranetproxy.alipay.com/skylark/lark/0/2020/png/305680/1590997565954-81b8860c-42c5-45df-bf2a-a9c2bd470766.png#align=left&display=inline&height=270&margin=%5Bobject%20Object%5D&name=image.png&originHeight=540&originWidth=1954&size=280626&status=done&style=none&width=977" srcset="/img/loading.gif" alt="image.png"><br><img src="https://intranetproxy.alipay.com/skylark/lark/0/2020/png/305680/1590992678139-ffb730ad-a80f-42bf-87d5-95413ae0a059.png#align=left&display=inline&height=804&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1608&originWidth=3004&size=1999601&status=done&style=none&width=1502" srcset="/img/loading.gif" alt="image.png"><br><img src="https://intranetproxy.alipay.com/skylark/lark/0/2020/png/305680/1590992713244-fbd5d447-0ca9-4319-b3e0-7590ecfc7f60.png#align=left&display=inline&height=826&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1652&originWidth=3006&size=2009880&status=done&style=none&width=1503" srcset="/img/loading.gif" alt="image.png"></p><p><img src="https://intranetproxy.alipay.com/skylark/lark/0/2020/png/305680/1590992731407-ee295d1c-a53f-4e86-9507-18463cab9a4a.png#align=left&display=inline&height=849&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1698&originWidth=2850&size=2093493&status=done&style=none&width=1425" srcset="/img/loading.gif" alt="image.png"></p><p><img src="https://intranetproxy.alipay.com/skylark/lark/0/2020/png/305680/1590992805830-2c8194e8-9f02-48b6-8bff-f3a0aa9c0b05.png#align=left&display=inline&height=822&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1644&originWidth=3014&size=1670759&status=done&style=none&width=1507" srcset="/img/loading.gif" alt="image.png"></p>]]></content>
    
    
    
    <tags>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>java设计规则引擎</title>
    <link href="/2020/07/05/java%E8%AE%BE%E8%AE%A1%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E/"/>
    <url>/2020/07/05/java%E8%AE%BE%E8%AE%A1%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E/</url>
    
    <content type="html"><![CDATA[<blockquote><p>用java设计一个规则引擎，要求首先抽象独立的规则，实现可插拔自定义的有序规则集</p><p>例如：结果有效的条件为满足顺序满足规则1，2，3</p><p>设计思路：将枚举与匿名内部类一起使用</p></blockquote><p>规则接口</p><pre><code class="hljs jade">public interface Rule &#123;    public Object apply(Object object);&#125;</code></pre><p>具体规则</p><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">enum</span>  ConcreteRule &#123;    RULE_ONE(<span class="hljs-keyword">new</span> Rule()&#123;        <span class="hljs-function"><span class="hljs-keyword">public</span> Object <span class="hljs-title">apply</span><span class="hljs-params">(Object object)</span> </span>&#123;            System.out.println(<span class="hljs-string">"RULE ONE"</span>);            <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;        &#125;    &#125;),    RULE_TWO(<span class="hljs-keyword">new</span> Rule() &#123;        <span class="hljs-function"><span class="hljs-keyword">public</span> Object <span class="hljs-title">apply</span><span class="hljs-params">(Object object)</span> </span>&#123;            System.out.println(<span class="hljs-string">"RULE TWO"</span>);            <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;        &#125;    &#125;),    RULE_THREE(<span class="hljs-keyword">new</span> Rule() &#123;        <span class="hljs-function"><span class="hljs-keyword">public</span> Object <span class="hljs-title">apply</span><span class="hljs-params">(Object object)</span> </span>&#123;            System.out.println(<span class="hljs-string">"RULE THREE"</span>);            <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;        &#125;    &#125;)    ;    <span class="hljs-keyword">private</span> Rule rule;    ConcreteRule(Rule rule) &#123;        <span class="hljs-keyword">this</span>.rule = rule;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> Object <span class="hljs-title">apply</span><span class="hljs-params">(Object object)</span></span>&#123;        <span class="hljs-keyword">return</span> rule.apply(object);    &#125;&#125;</code></pre><p>规则集</p><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RuleSet</span> </span>&#123;    <span class="hljs-keyword">private</span> List&lt;ConcreteRule&gt; rules;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">RuleSet</span><span class="hljs-params">()</span></span>&#123;        rules = <span class="hljs-keyword">new</span> ArrayList&lt;ConcreteRule&gt;();    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">add</span><span class="hljs-params">(ConcreteRule rule)</span></span>&#123;        rules.add(rule);    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> Object <span class="hljs-title">apply</span><span class="hljs-params">(Object object)</span></span>&#123;        <span class="hljs-keyword">for</span> (ConcreteRule rule : rules)&#123;            rule.apply(object);        &#125;        System.out.println(<span class="hljs-string">"rules apply over!"</span>);        <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;    &#125;&#125;</code></pre><p>规则工厂</p><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RuleSets</span> </span>&#123;    <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-title">RuleSets</span><span class="hljs-params">()</span></span>&#123;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> RuleSet <span class="hljs-title">isXXX</span><span class="hljs-params">()</span></span>&#123;        RuleSet ruleSet = <span class="hljs-keyword">new</span> RuleSet();        ruleSet.add(ConcreteRule.RULE_ONE);        ruleSet.add(ConcreteRule.RULE_TWO);        ruleSet.add(ConcreteRule.RULE_THREE);        <span class="hljs-keyword">return</span> ruleSet;    &#125;&#125;</code></pre><p>Main函数</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;  Object a = <span class="hljs-keyword">new</span> Object();  RuleSet ruleSet = RuleSets.isXXX();  ruleSet.apply(a);&#125;</code></pre><ul><li>TODO：可以考虑lambda表达式简化构造</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>java设计模式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Epoll</title>
    <link href="/2020/07/05/Epoll/"/>
    <url>/2020/07/05/Epoll/</url>
    
    <content type="html"><![CDATA[<h4 id="Select-Epoll"><a href="#Select-Epoll" class="headerlink" title="Select,Epoll"></a>Select,Epoll</h4><ul><li><p>一次ＩＯ访问，需要先将数据拷贝进内核缓冲区，再拷贝到应用程序地址空间。</p></li><li><p>阻塞</p></li><li><ul><li>进程发起read请求，等待状态下进程主动阻塞</li></ul></li><li><p>非阻塞</p></li><li><ul><li>进程不断的主动询问内核，返回ｅｒｒｏｒ</li></ul></li><li><p>I/O多路复用</p></li><li><ul><li>单个process就可以同时处理多个网络连接的IO，select，poll，epoll这个function会不断的轮询所负责的所有socket，，当某个socket有数据到达了，就通知用户进程。</li></ul></li><li><p>如何知道接收了数据：</p></li><li><ul><li>网卡把数据写入内存后，向cpu发出一个中断信号，操作系统就知道有新数据来了</li></ul></li><li><p>阻塞为什么不占用cpu资源</p></li><li><ul><li>进程阻塞，进入等待队列（从cpu轮询的工作队列中移出），socket创建一个由文件系统管理的对象，这个socket对象包含了发送接收缓冲区以及等待队列的成员，当网卡通知cpu有数据到达，cpu执行中断程序，把网络数据写入socket接收缓冲区，再唤醒等待队列的进程</li></ul></li><li><p>如何同时监视多个socket的数据？</p></li><li><p>select：</p></li><li><ul><li><p>如果程序A同时监视多个socket，那么就把该进程分别加入这多个socket的等待队列中，这样任何一个socket收到数据，都会唤醒进程，但之后程序需要遍历socket列表，才能得到具体是哪个socket就绪了。</p></li><li><p>缺点：</p></li><li><ul><li>每次调用需要把进程加入所有监视的socket等待队列中，每次唤醒也需要遍历寻找和移除，因此每次都要将整个FDS列表传给内核，开销很大。</li><li>最大监视数1024</li></ul></li></ul></li><li><p>epoll：</p></li><li><ul><li><p>功能分离，用epoll_ctl维护等待队列，用epoll_wait阻塞进程</p></li><li><p>epoll_create:内核创建一个event poll对象，也是文件系统一员，有自己的等待队列</p></li><li><ul><li>就绪列表rdlist，保存所有就绪的socket，避免遍历（双向链表实现）</li><li>等待队列，连进程</li><li>索引结构，保存socket，用红黑树</li></ul></li><li><p>监视过程变为把eventpoll对象添加到每个socket的等待队列中，收到数据后，中断程序要做的是操作eventpoll对象，给rdlist添加socket引用，所以当epoll_wait的时候，如果rdlist不为空直接返回</p></li></ul></li><li><p>水平触发与边缘触发</p></li><li><ul><li>水平触发：每次文件描述符就绪后，一遍一次IO没有执行完，下次epoll_wait时还是就绪态，还可以继续执行。只要缓冲区不空就可以读，不满就可以写，如果没有一次性读写完，下次还会提示就绪并读写。这样系统中如果有很多并不需要读写但是就绪的文件描述符，每次都要返回。降低了效率。</li><li>边缘触发：如果一次没有执行完，直到下次IO可读写事件发生前都不会再有通知，也就是只要0变1的上升沿才会触发，丢失了剩余的数据。在发生文件描述符就绪时，采用非阻塞的方式尽可能多的进行IO。</li></ul></li></ul><ul><li><p>高并发场景下，对消息的读取和分割可能和epoll_wait在不同的线程中，这时候如果选择LT，那么在读完数据前，epoll_wait会不停的无谓醒来。</p></li><li><p>饥饿现象：</p></li><li><ul><li>在边缘触发条件下，存在某个就绪的文件描述符上有大量的输入，会出现饥饿现象</li></ul></li></ul><h4 id="用epoll实现定时器"><a href="#用epoll实现定时器" class="headerlink" title="用epoll实现定时器"></a>用epoll实现定时器</h4><h4 id="用epoll处理signal"><a href="#用epoll处理signal" class="headerlink" title="用epoll处理signal"></a>用epoll处理signal</h4><p>将signal转换为对一个文件描述符的读写，初始化一个管道，一端read，一端write，其中read添加到epoll中，这样当信号来的时候，将信号写入wirte端，read端的文件描述符上的read事件被触发，epoll_wait就返回了</p>]]></content>
    
    
    
    <tags>
      
      <tag>操作系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>进程与线程</title>
    <link href="/2020/07/05/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/"/>
    <url>/2020/07/05/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<ul><li><p>进程是操作系统分配资源的最小单位，是程序的实体，操作系统运行一个程序，那这个程序就是一个进程，每个进程有自己的pid进程号。操作系统会为进程分配一块内存。</p></li><li><p>而线程包含在进程之中，一个进程可以并发多个线程，但这里的并发是在cpu时间片上的串行执行，同一个进程中的线程共享进程包括内存的所有资源，而每个线程只需要分配自己的一个程序计数器，栈，寄存器这些东西。在线程上的切换是由内核根据这些完成的。</p></li><li><p>在进程中可以创建fork一个子进程，调用系统的clone操作，在内核中创建出一个task对象，并返回子进程号，区别在于是否拷贝内存，当然拷贝的话现在的操作系统也是拷贝索引。</p></li><li><p>进程控制块PCB（数据结构）</p></li><li><ul><li><p>pid</p></li><li><p>user</p></li><li><p>ppid</p></li><li><p>状态保存区，栈，pc，寄存器</p></li><li><p>控制信息</p></li><li><ul><li>状态</li><li>通信信息</li><li>所用资源</li><li>进程链</li></ul></li></ul></li><li><p>进程 = 资源平台+执行线程</p></li><li><p>线程能够减少并发执行的时间和空间，比进程创建和结束的时间短，切换时间短，可直接进行不通过内核的通信</p></li><li><p>CPU对进程的管理</p></li><li><p>进程状态</p></li><li><ul><li><p>创建</p></li><li><ul><li><p>为子进程分配内存fork</p></li><li><p>复制父进程内存和cpu寄存器到子进程</p></li><li><p>exec加载并执行，使得上一步对父进程的复制没有作用了</p></li><li><ul><li>可以通过vfork优化，分配内存后直接exec</li><li>cow写时复制，利用虚存管理，只复制页表，共享的读，只有写时复制双份</li></ul></li></ul></li><li><p>就绪</p></li><li><ul><li>阻塞态被唤醒进入就绪态</li><li>运行态遇到时间片调度，进入就绪态</li><li>中断产生，运行态进入就绪态</li></ul></li><li><p>运行</p></li><li><p>阻塞</p></li><li><ul><li>进程自我阻塞，select，sleep等</li></ul></li><li><p>结束（僵尸）</p></li><li><ul><li>wait父进程等待子进程结束，帮助销毁回收内核中的僵尸PCB数据</li><li>exit只能释放自己的内存，关闭文件连接，释放内存，检查父进程是否存活，清理僵尸进程</li></ul></li></ul></li><li><p>cpu调度</p></li><li><ul><li><p>从就绪队列中选择一个进程/线程，进入运行态</p></li><li><p>上下文切换</p></li><li><ul><li>切换当前cpu任务，从一个进程/线程进入下一个</li><li>保存当前pcb/tcb中的上下文cpu状态</li><li>读取下一个进程/线程的上下文</li></ul></li><li><p>原则</p></li><li><ul><li>cpu使用率，吞吐量（单位时间总完成），周转时间，等待时间，响应时间，公平</li></ul></li><li><p>策略</p></li><li><ul><li><p>FCFS先来先服务</p></li><li><p>短进程优先</p></li><li><p>最高响应比优先R = （等待+执行）/等待</p></li><li><p>轮询（定义合适的时间片，减少上下文切换开销）</p></li><li><p>多级反馈队列</p></li><li><ul><li>多级，高优先级队列先执行</li><li>各个队列内部可以选择不同的策略</li><li>反馈，任务随着运行时间动态优先级下降和上升</li></ul></li><li><p>公平共享调度，面对多用户</p></li></ul></li><li><p>优先级反转</p></li><li><ul><li>ABC优先级任务，C占用了x资源，A等待x资源即等待C的释放，但B优先级高于C，所以C需要等待B，导致A被低优先级B影响</li><li>优先级继承，或设置资源优先级</li></ul></li></ul></li><li><p>linux调度器</p></li><li><ul><li><p>O（n）</p></li><li><ul><li>就绪队列遍历问题</li><li>多核cpu扩展性问题，通过自旋锁满足多个cpu对队列的并发访问</li><li>cpu空转问题，全部进程时间片被耗尽后需要重新计算时间片</li><li>一个进程会在多个cpu上跳来跳去</li><li>实时调度性能一般</li></ul></li><li><p>O（1）</p></li><li><ul><li>每个CPU都有一个runable队列，把大锁变成小锁</li><li>优先级反馈队列</li><li>负载层</li><li>抢占式内核</li></ul></li><li><p>CFS</p></li><li><ul><li>CFS调度器的公平就是保证所有的可运行状态的进程按照权重分配其CPU资源</li><li>红黑树，虚拟时间轴</li></ul></li></ul></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>操作系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
